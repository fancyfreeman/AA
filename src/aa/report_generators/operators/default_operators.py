"""
é»˜è®¤æ“ä½œç¬¦æ¨¡å—

è¯¥æ¨¡å—åŒ…å«äº†ä¸€ç³»åˆ—ç”¨äºç”ŸæˆæŠ¥å‘Šçš„é»˜è®¤æ“ä½œç¬¦ç±»ï¼ŒåŒ…æ‹¬:
- å½“æœŸå€¼æ“ä½œç¬¦
- æ’åæ“ä½œç¬¦
- è¶‹åŠ¿æ“ä½œç¬¦
- å®Œæˆç‡æ“ä½œç¬¦
- åŒæ¯”æ“ä½œç¬¦
- ç¯æ¯”æ“ä½œç¬¦

æ¯ä¸ªæ“ä½œç¬¦éƒ½ç»§æ‰¿è‡ªBaseOperatoråŸºç±»ï¼Œå®ç°äº†ç‰¹å®šçš„æ•°æ®å¤„ç†å’Œæ ¼å¼åŒ–é€»è¾‘ã€‚
"""

import logging
from typing import Union
import pandas as pd
from aa.report_generators.operators.base_operator import BaseOperator

logger = logging.getLogger(__name__)

# é»˜è®¤å€¼ï¼Œå°†åœ¨åˆå§‹åŒ–æ—¶è¢«æ›¿æ¢
ASC_ORDERED_KEYWORDS = [
    "ä¸è‰¯ç‡",
    "æˆæœ¬ç‡",
    "åŒä¸šæ’å",
    "æ’å",
    "é›¶å”®ç»¼åˆè€ƒè¯„ç­‰çº§",
    "é€€è´§ç‡",
    "æˆæœ¬",
    "åº“å­˜é‡ï¼ˆä»¶ï¼‰",
]
PERCENTAGE_KEYWORDS = ["ç‡", "å æ¯”", "å®šä»·", "æ¯”ä¾‹"]


# ç”¨äºæ›´æ–°å…³é”®è¯åˆ—è¡¨çš„å‡½æ•°
def update_keywords(asc_ordered_keywords=None, percentage_keywords=None):
    """
    æ›´æ–°æ¨¡å—ä¸­ä½¿ç”¨çš„å…³é”®è¯åˆ—è¡¨

    Args:
        asc_ordered_keywords: å‡åºæ’åºå…³é”®è¯åˆ—è¡¨
        percentage_keywords: ç™¾åˆ†æ¯”å…³é”®è¯åˆ—è¡¨
    """
    global ASC_ORDERED_KEYWORDS, PERCENTAGE_KEYWORDS
    if (asc_ordered_keywords is not None) and (percentage_keywords is not None):
        ASC_ORDERED_KEYWORDS = asc_ordered_keywords
        PERCENTAGE_KEYWORDS = percentage_keywords
        logger.info(f"å·²æ›´æ–°ASC_ORDERED_KEYWORDS: {ASC_ORDERED_KEYWORDS}")
        logger.info(f"å·²æ›´æ–°PERCENTAGE_KEYWORDS: {PERCENTAGE_KEYWORDS}")


def pp(indicator, value) -> str:
    """ç¾åŒ–è¾“å‡ºå€¼"""
    # ç”¨äºæ ¼å¼åŒ–è¾“å‡ºæ•°å€¼
    if "æ’å" in indicator and ("åŒæ¯”" in indicator or "ç¯æ¯”" in indicator):
        rank_change = int(value)
        if rank_change == 0:
            res = "æ’åä½æ¬¡ä¸å˜"
        else:
            res = f"æ’åä½æ¬¡{"ä¸Šå‡" if value <0 else "ä¸‹é™" }{abs(int(value)):d}ä½"
    elif "æ’å" in indicator:
        rank_change = int(value)
        res = f"ç¬¬{rank_change:d}å"
    elif any(keyword in indicator for keyword in ["æˆæœ¬ç‡", "å®šä»·"]) and (
        "åŒæ¯”" in indicator or "ç¯æ¯”" in indicator
    ):
        bps = int(value * 10000)
        res = f"{bps:+d}Bps"
    elif any(keyword in indicator for keyword in ["å æ¯”", "æ¯”ä¾‹"]) and (
        "åŒæ¯”" in indicator or "ç¯æ¯”" in indicator
    ):
        percentage = value * 100
        res = f"{percentage:.2f}ä¸ªç™¾åˆ†ç‚¹"
    elif any(keyword in indicator for keyword in PERCENTAGE_KEYWORDS):
        res = f"{value:.2%}"
    elif "å®¢æˆ·æ•°" in indicator:
        res = f"{int(value)}"
    elif "é›¶å”®ç»¼åˆè€ƒè¯„ç­‰çº§" in indicator:
        mapping = {1: "A", 2: "B", 3: "C"}
        res = mapping.get(value)
    else:
        res = f"{value:.1f}"
    return res


class CurrentValueOperator(BaseOperator):
    """å¤„ç†å½“æœŸå€¼æ“ä½œç¬¦"""

    @classmethod
    def handle(
        cls, config: dict, all_data_df: pd.DataFrame, all_data_melted_df: pd.DataFrame
    ) -> str:
        # è·å–æŸ¥è¯¢å‚æ•°
        try:
            target_date = pd.to_datetime(config["data_dt_rule"]).normalize()
            org = config["org_name"]
            indicator = config["indicator"]
        except KeyError as e:
            return f"è®¡ç®—å½“æœŸå€¼æ—¶ï¼šæŸ¥è¯¢æŒ‡æ ‡æ•°æ®å‡ºé”™{str(e)}"

        # æ‰§è¡Œæ•°æ®æŸ¥è¯¢
        try:
            filtered = all_data_melted_df[
                (
                    pd.to_datetime(all_data_melted_df["æ•°æ®æ—¥æœŸ"]).dt.normalize()
                    == target_date
                )
                & (all_data_melted_df["æœºæ„åç§°"] == org)
                & (all_data_melted_df["æŒ‡æ ‡åç§°"] == indicator)
            ]

            # æ£€æŸ¥æŸ¥è¯¢ç»“æœæœ‰æ•ˆæ€§
            if len(filtered) == 0:
                return "è®¡ç®—å½“æœŸå€¼æ—¶ï¼šæŸ¥è¯¢æŒ‡æ ‡æ•°æ®å‡ºé”™ï¼Œè®°å½•æ•°ä¸º0ï¼Œè¯·æ£€æŸ¥æ•°æ®æ˜¯å¦å®Œæ•´"

            values = filtered["æŒ‡æ ‡å€¼"].dropna().unique()
            if len(values) != 1:
                return "è®¡ç®—å½“æœŸå€¼æ—¶ï¼šæŸ¥è¯¢æŒ‡æ ‡æ•°æ®å‡ºé”™ï¼Œè®°å½•æ•°ä¸ä¸º1ï¼Œè¯·æ£€æŸ¥æ•°æ®æ˜¯å¦é‡å¤"

            sentiment = get_sentiment(
                operator="CurrentValueOperator", indicator=indicator
            )
            return f"{sentiment}å½“æœŸå€¼ï¼š{pp(indicator,values[0])}"

        except Exception as e:
            return f"è®¡ç®—å½“æœŸå€¼æ—¶ï¼šæŸ¥è¯¢æŒ‡æ ‡æ•°æ®å‡ºé”™{str(e)}"

class RankingOperator(BaseOperator):
    """å¤„ç†ç»„å†…æ’åæ“ä½œç¬¦"""

    @classmethod
    def handle(
        cls, config: dict, all_data_df: pd.DataFrame, all_data_melted_df: pd.DataFrame
    ) -> str:
        try:
            # è·å–æŸ¥è¯¢å‚æ•°
            target_date = pd.to_datetime(config["data_dt_rule"]).normalize()
            org = config["org_name"]
            indicator = config["indicator"]
            format = config["format"]
        except KeyError as e:
            return f"è®¡ç®—ç»„å†…æ’åæ—¶ï¼šæŸ¥è¯¢æŒ‡æ ‡æ•°æ®å‡ºé”™{str(e)}"

        try:
            # è·å–å½“å‰æœºæ„çš„æœºæ„åˆ†ç»„
            current_org_data = all_data_melted_df[
                (
                    pd.to_datetime(all_data_melted_df["æ•°æ®æ—¥æœŸ"]).dt.normalize()
                    == target_date
                )
                & (all_data_melted_df["æœºæ„åç§°"] == org)
                & (all_data_melted_df["æŒ‡æ ‡åç§°"] == indicator)
            ]

            if current_org_data.empty:
                return "è®¡ç®—ç»„å†…æ’åæ—¶ï¼šæŸ¥è¯¢æŒ‡æ ‡æ•°æ®å‡ºé”™ï¼Œè¯·æ£€æŸ¥æ•°æ®æ˜¯å¦å®Œæ•´"

            branch_group = current_org_data["æœºæ„åˆ†ç»„"].iloc[0]

            # è·å–åŒåˆ†ç»„æ‰€æœ‰æœºæ„æ•°æ®
            group_data = all_data_melted_df[
                (
                    pd.to_datetime(all_data_melted_df["æ•°æ®æ—¥æœŸ"]).dt.normalize()
                    == target_date
                )
                & (all_data_melted_df["æœºæ„åˆ†ç»„"] == branch_group)
                & (all_data_melted_df["æŒ‡æ ‡åç§°"] == indicator)
            ]

            if group_data.empty:
                return "è®¡ç®—ç»„å†…æ’åæ—¶ï¼šæŸ¥è¯¢æŒ‡æ ‡æ•°æ®å‡ºé”™ï¼Œæœºæ„åˆ†ç»„æ•°æ®ä¸ºç©ºï¼Œè¯·æ£€æŸ¥æœºæ„åˆ†ç»„å‚æ•°æ˜¯å¦é…ç½®"

            # å»é™¤é‡å¤æœºæ„æ•°æ®ï¼ˆä¿ç•™æœ€åä¸€ä¸ªï¼‰
            dedup_data = group_data.drop_duplicates(subset=["æœºæ„åç§°"], keep="last")

            # æ£€æŸ¥ indicator æ˜¯å¦åŒ…å«åˆ—è¡¨ä¸­çš„å…³é”®è¯
            ascending_sort = any(
                keyword in indicator for keyword in ASC_ORDERED_KEYWORDS
            )

            sorted_df = dedup_data.sort_values(by="æŒ‡æ ‡å€¼", ascending=ascending_sort)

            # è®¡ç®—æ’åï¼ˆå¤„ç†å¹¶åˆ—æƒ…å†µï¼‰
            sorted_df["æ’å"] = (
                sorted_df["æŒ‡æ ‡å€¼"]
                .rank(method="min", ascending=ascending_sort)
                .astype(int)
            )

            # æŸ¥æ‰¾å½“å‰æœºæ„æ’å
            org_rank = sorted_df.loc[sorted_df["æœºæ„åç§°"] == org, "æ’å"].values

            if len(org_rank) == 0:
                return "è®¡ç®—ç»„å†…æ’åæ—¶ï¼šæŸ¥è¯¢æŒ‡æ ‡æ•°æ®å‡ºé”™ï¼Œè®°å½•æ•°ä¸º0ï¼Œè¯·æ£€æŸ¥æ•°æ®æ˜¯å¦å®Œæ•´"
            # ç”Ÿæˆç»„å†…åˆ†è¡Œæ’åè¯¦æƒ…
            rank_details = []
            for idx, row in sorted_df.iterrows():
                rank = row["æ’å"]
                branch = row["æœºæ„åç§°"]
                value = row["æŒ‡æ ‡å€¼"]
                rank_details.append(f"No{rank}.{branch}ï¼ˆ{pp(indicator,value)}ï¼‰")

            if format == "A":
                sentiment = get_sentiment(
                    operator="RankingOperator",
                    indicator=indicator,
                    group_rank_participant_count=len(sorted_df),
                    rank=org_rank[0]
                )
                return f"{sentiment}ç»„å†…æ’åï¼šç¬¬{org_rank[0]}åï¼ˆç»„å†…å…±{len(sorted_df)}å®¶æœºæ„ï¼‰ï¼›ç»„å†…æ’åé¡ºåºä¸ºï¼š{'ï¼Œ '.join(rank_details)}"
            else:
                return (
                    "=====" * (len(sorted_df) + 1 - org_rank[0])
                    + f"ï¼ˆç¬¬{org_rank[0]}åï¼‰"
                )

        except Exception as e:
            return f"è®¡ç®—ç»„å†…æ’åæ—¶ï¼šæŸ¥è¯¢æŒ‡æ ‡æ•°æ®å‡ºé”™ {str(e)}"


class TrendLast3MonthsOperator(BaseOperator):
    """å¤„ç†è¿‘3æœˆè¶‹åŠ¿æ“ä½œç¬¦"""

    @classmethod
    def handle(
        cls, config: dict, all_data_df: pd.DataFrame, all_data_melted_df: pd.DataFrame
    ) -> str:
        try:
            # è§£æåŸºç¡€å‚æ•°
            target_date = pd.to_datetime(config["data_dt_rule"]).normalize()
            org = config["org_name"]
            indicator = config["indicator"]
        except KeyError as e:
            return f"è®¡ç®—è¿‘3æœˆè¶‹åŠ¿æ—¶ï¼šæŸ¥è¯¢æŒ‡æ ‡æ•°æ®å‡ºé”™{str(e)}"

        try:
            # ç”Ÿæˆéœ€è¦æŸ¥è¯¢çš„ä¸‰ä¸ªæœˆèŒƒå›´ï¼ˆT-2ã€T-1ã€Tï¼‰
            months = [target_date - pd.DateOffset(months=x) for x in [2, 1, 0]]
            # å¯¹ months ä¸­çš„æ¯ä¸ªæ—¥æœŸåŠ ä¸Š pd.offsets.MonthEnd(0)
            month_ends = [date + pd.offsets.MonthEnd(0) for date in months]

            # è¿‡æ»¤ç›®æ ‡æ•°æ®
            filtered = all_data_melted_df[
                (all_data_melted_df["æœºæ„åç§°"] == org)
                & (all_data_melted_df["æŒ‡æ ‡åç§°"] == indicator)
                & (all_data_melted_df["æ•°æ®æ—¥æœŸ"].isin(month_ends))
            ]

            # æœ‰æ•ˆæ€§æ£€æŸ¥åŸºç¡€æ•°æ®
            if filtered.empty:
                return "è®¡ç®—è¿‘3æœˆè¶‹åŠ¿æ—¶ï¼šæŸ¥è¯¢æŒ‡æ ‡æ•°æ®å‡ºé”™ï¼Œæ•°æ®é›†ä¸ºç©º"

            # æŒ‰æ—¥æœŸæ’åºåå»é‡ï¼ˆä¿ç•™æ¯ä¸ªæœˆä»½æœ€åä¸€ä¸ªè®°å½•ï¼‰
            filtered = filtered.sort_values("æ•°æ®æ—¥æœŸ")
            dedup_data = filtered.drop_duplicates(subset=["æ•°æ®æ—¥æœŸ"], keep="last")

            # æ£€æŸ¥æ˜¯å¦åŒ…å«å®Œæ•´ä¸‰ä¸ªæœˆæ•°æ®
            existing_months = dedup_data["æ•°æ®æ—¥æœŸ"].unique()
            if not all(m in existing_months for m in month_ends):
                return "è®¡ç®—è¿‘3æœˆè¶‹åŠ¿æ—¶ï¼šæŸ¥è¯¢æŒ‡æ ‡æ•°æ®å‡ºé”™ï¼Œæ•°æ®æ—¥æœŸä¸å®Œæ•´ï¼Œæ•°æ®åº”åŒ…å«è¿‘3ä¸ªæœˆæœ«çš„æ•°æ®"

            # æŒ‰æ—¶é—´é¡ºåºæå–æŒ‡æ ‡å€¼ï¼ˆT-2ã€T-1ã€Tï¼‰
            trend_data = dedup_data.set_index("æ•°æ®æ—¥æœŸ").loc[month_ends]
            values = trend_data["æŒ‡æ ‡å€¼"].tolist()

            # æœ€ç»ˆæœ‰æ•ˆæ€§æ£€æŸ¥
            if len(values) != 3 or any(pd.isnull(values)):
                return "è®¡ç®—è¿‘3æœˆè¶‹åŠ¿æ—¶ï¼šæŸ¥è¯¢æŒ‡æ ‡æ•°æ®å‡ºé”™ï¼Œæ•°æ®æ—¥æœŸä¸å®Œæ•´ï¼Œæ•°æ®åº”åŒ…å«è¿‘3ä¸ªæœˆæœ«çš„æ•°æ®"

            v1, v2, v3 = values

            indicator_value = f"è¿‘3æœˆæŒ‡æ ‡å€¼ä¸ºï¼š{pp(indicator,v1)} {pp(indicator,v2)} {pp(indicator,v3)}"

            # æ£€æŸ¥ indicator æ˜¯å¦åŒ…å«åˆ—è¡¨ä¸­çš„å…³é”®è¯
            if any(keyword in indicator for keyword in ASC_ORDERED_KEYWORDS):
                rank = "ASC"
            else:
                rank = "DESC"

            # åˆ¤æ–­è¶‹åŠ¿ç±»å‹
            result = ""
            if v1 < v2 < v3:
                mean_of_trend = et("up", rank)
                result = f"è¿‘3æœˆè¶‹åŠ¿ï¼šè¿ç»­2æœˆ{mean_of_trend}ã€‚{indicator_value}"
            elif v1 > v2 > v3:
                mean_of_trend = et("down", rank)
                result = f"è¿‘3æœˆè¶‹åŠ¿ï¼šè¿ç»­2æœˆ{mean_of_trend}ã€‚{indicator_value}"
            elif v1 <= v2 and v2 > v3:
                mean_of_trend = et("down", rank)
                result = f"è¿‘3æœˆè¶‹åŠ¿ï¼šå‡ºç°æ‹ç‚¹ï¼Œå¼€å§‹{mean_of_trend}ã€‚{indicator_value}"
            elif v1 >= v2 and v2 < v3:
                mean_of_trend = et("up", rank)
                result = f"è¿‘3æœˆè¶‹åŠ¿ï¼šå‡ºç°æ‹ç‚¹ï¼Œå¼€å§‹{mean_of_trend}ã€‚{indicator_value}"
            elif v1 == v2 and v2 == v3:
                result = f"è¿‘3æœˆè¶‹åŠ¿ï¼šæŒå¹³ã€‚{indicator_value}"
            else:
                result = f"è¿‘3æœˆè¶‹åŠ¿ï¼šæ³¢åŠ¨ã€‚{indicator_value}"

            sentiment = get_sentiment(
                operator="TrendLast3MonthsOperator",
                indicator=indicator,
                result_str=result
            )
            return f"{sentiment}{result}"

        except Exception as e:
            return f"è®¡ç®—è¿‘3æœˆè¶‹åŠ¿æ—¶ï¼šæŸ¥è¯¢æŒ‡æ ‡æ•°æ®å‡ºé”™{str(e)}"


class TrendLast3QuartersOperator(BaseOperator):
    """å¤„ç†è¿‘3å­£åº¦è¶‹åŠ¿æ“ä½œç¬¦"""

    @classmethod
    def handle(
        cls, config: dict, all_data_df: pd.DataFrame, all_data_melted_df: pd.DataFrame
    ) -> str:
        try:
            # è§£æåŸºç¡€å‚æ•°
            target_date = pd.to_datetime(config["data_dt"]).normalize()
            org = config["org_name"]
            indicator = config["indicator"]
        except KeyError as e:
            return f"è®¡ç®—è¿‘3å­£åº¦è¶‹åŠ¿æ—¶ï¼šæŸ¥è¯¢æŒ‡æ ‡æ•°æ®å‡ºé”™{str(e)}"

        try:
            # ç”Ÿæˆéœ€è¦æŸ¥è¯¢çš„ä¸‰ä¸ªå­£åº¦èŒƒå›´ï¼ˆT-2ã€T-1ã€Tï¼‰
            # è®¡ç®—å½“å‰å­£åº¦æœ«
            current_quarter_end = target_date + pd.offsets.QuarterEnd(0)

            # ç”Ÿæˆä¸‰ä¸ªå­£åº¦çš„å­£æœ«æ—¥æœŸ
            quarters = [target_date - pd.DateOffset(months=x) for x in [6, 3, 0]]
            quarter_ends = [date + pd.offsets.MonthEnd(0) for date in quarters]

            # è¿‡æ»¤ç›®æ ‡æ•°æ®
            filtered = all_data_melted_df[
                (all_data_melted_df["æœºæ„åç§°"] == org)
                & (all_data_melted_df["æŒ‡æ ‡åç§°"] == indicator)
                & (all_data_melted_df["æ•°æ®æ—¥æœŸ"].isin(quarter_ends))
            ]

            # æœ‰æ•ˆæ€§æ£€æŸ¥åŸºç¡€æ•°æ®
            if filtered.empty:
                return "è®¡ç®—è¿‘3å­£åº¦è¶‹åŠ¿æ—¶ï¼šæŸ¥è¯¢æŒ‡æ ‡æ•°æ®å‡ºé”™ï¼Œæ•°æ®é›†ä¸ºç©º"

            # æŒ‰æ—¥æœŸæ’åºåå»é‡ï¼ˆä¿ç•™æ¯ä¸ªå­£åº¦æœ€åä¸€ä¸ªè®°å½•ï¼‰
            filtered = filtered.sort_values("æ•°æ®æ—¥æœŸ")
            dedup_data = filtered.drop_duplicates(subset=["æ•°æ®æ—¥æœŸ"], keep="last")

            # æ£€æŸ¥æ˜¯å¦åŒ…å«å®Œæ•´ä¸‰ä¸ªå­£åº¦æ•°æ®
            existing_quarters = dedup_data["æ•°æ®æ—¥æœŸ"].unique()
            if not all(q in existing_quarters for q in quarter_ends):
                return "è®¡ç®—è¿‘3å­£åº¦è¶‹åŠ¿æ—¶ï¼šæŸ¥è¯¢æŒ‡æ ‡æ•°æ®å‡ºé”™ï¼Œæ•°æ®æ—¥æœŸä¸å®Œæ•´ï¼Œæ•°æ®åº”åŒ…å«è¿‘3ä¸ªå­£åº¦æœ«çš„æ•°æ®"

            # æŒ‰æ—¶é—´é¡ºåºæå–æŒ‡æ ‡å€¼ï¼ˆT-2ã€T-1ã€Tï¼‰
            trend_data = dedup_data.set_index("æ•°æ®æ—¥æœŸ").loc[quarter_ends]
            values = trend_data["æŒ‡æ ‡å€¼"].tolist()

            # æœ€ç»ˆæœ‰æ•ˆæ€§æ£€æŸ¥
            if len(values) != 3 or any(pd.isnull(values)):
                return "è®¡ç®—è¿‘3å­£åº¦è¶‹åŠ¿æ—¶ï¼šæŸ¥è¯¢æŒ‡æ ‡æ•°æ®å‡ºé”™ï¼Œæ•°æ®æ—¥æœŸä¸å®Œæ•´ï¼Œæ•°æ®åº”åŒ…å«è¿‘3ä¸ªå­£åº¦æœ«çš„æ•°æ®"

            v1, v2, v3 = values
            indicator_value = f"è¿‘3å­£åº¦æŒ‡æ ‡å€¼ä¸ºï¼š{pp(indicator,v1)} {pp(indicator,v2)} {pp(indicator,v3)}"

            # æ£€æŸ¥ indicator æ˜¯å¦åŒ…å«åˆ—è¡¨ä¸­çš„å…³é”®è¯
            if any(keyword in indicator for keyword in ASC_ORDERED_KEYWORDS):
                rank = "ASC"
            else:
                rank = "DESC"

            # åˆ¤æ–­è¶‹åŠ¿ç±»å‹
            result = ""
            if v1 < v2 < v3:
                mean_of_trend = et("up", rank)
                result = f"è¿‘3å­£åº¦è¶‹åŠ¿ï¼šè¿ç»­2å­£åº¦{mean_of_trend}ã€‚{indicator_value}"
            elif v1 > v2 > v3:
                mean_of_trend = et("down", rank)
                result = f"è¿‘3å­£åº¦è¶‹åŠ¿ï¼šè¿ç»­2å­£åº¦{mean_of_trend}ã€‚{indicator_value}"
            elif v1 <= v2 and v2 > v3:
                mean_of_trend = et("down", rank)
                result = (
                    f"è¿‘3å­£åº¦è¶‹åŠ¿ï¼šå‡ºç°æ‹ç‚¹ï¼Œå¼€å§‹{mean_of_trend}ã€‚{indicator_value}"
                )
            elif v1 >= v2 and v2 < v3:
                mean_of_trend = et("up", rank)
                result = (
                    f"è¿‘3å­£åº¦è¶‹åŠ¿ï¼šå‡ºç°æ‹ç‚¹ï¼Œå¼€å§‹{mean_of_trend}ã€‚{indicator_value}"
                )
            elif v1 == v2 and v2 == v3:
                result = f"è¿‘3å­£åº¦è¶‹åŠ¿ï¼šæŒå¹³ã€‚{indicator_value}"
            else:
                result = f"è¿‘3å­£åº¦è¶‹åŠ¿ï¼šæ³¢åŠ¨ã€‚{indicator_value}"

            sentiment = get_sentiment(
                operator="TrendLast3QuartersOperator",
                indicator=indicator,
                result_str=result,
            )
            return f"{sentiment}{result}"

        except Exception as e:
            return f"è®¡ç®—è¿‘3å­£åº¦è¶‹åŠ¿æ—¶ï¼šæŸ¥è¯¢æŒ‡æ ‡æ•°æ®å‡ºé”™{str(e)}"


class TrendLast3YearsOperator(BaseOperator):
    """å¤„ç†è¿‘3å¹´è¶‹åŠ¿æ“ä½œç¬¦"""

    @classmethod
    def handle(
        cls, config: dict, all_data_df: pd.DataFrame, all_data_melted_df: pd.DataFrame
    ) -> str:
        try:
            # è§£æåŸºç¡€å‚æ•°
            # normalize()å°†æ—¶é—´æˆ³è§„èŒƒåŒ–åˆ°å½“å¤©çš„åˆå¤œæ—¶é—´ç‚¹(00:00:00)
            # ä¾‹å¦‚: 2024-03-14 13:45:30 -> 2024-03-14 00:00:00
            # è¿™æ ·å¯ä»¥ç¡®ä¿åœ¨æ¯”è¾ƒæ—¥æœŸæ—¶å¿½ç•¥å…·ä½“æ—¶åˆ†ç§’,åªå…³æ³¨å¹´æœˆæ—¥
            target_date = pd.to_datetime(config["data_dt"]).normalize()
            org = config["org_name"]
            indicator = config["indicator"]
        except KeyError as e:
            return f"è®¡ç®—è¿‘3å¹´è¶‹åŠ¿æ—¶ï¼šæŸ¥è¯¢æŒ‡æ ‡æ•°æ®å‡ºé”™{str(e)}"

        # åˆ¤æ–­æ˜¯å¦ä¸ºå¹´æœ«
        if target_date.month == 12 and target_date.day == 31:
            current_year_end = target_date
        else:
            # è·å–target_dateæ‰€åœ¨å¹´çš„å¹´æœ«æ—¥æœŸ
            # target_dateæ˜¯pd.Timestampç±»å‹,ä¸ºä¿æŒä¸€è‡´ä¹Ÿä½¿ç”¨pd.Timestamp
            current_year_end = pd.Timestamp(target_date.year - 1, 12, 31).normalize()

        try:
            # ç”Ÿæˆéœ€è¦æŸ¥è¯¢çš„ä¸‰ä¸ªå¹´åº¦èŒƒå›´ï¼ˆT-2ã€T-1ã€Tï¼‰
            years = [current_year_end - pd.DateOffset(years=x) for x in [12, 1, 0]]
            # ç”Ÿæˆä¸‰ä¸ªå¹´åº¦çš„å¹´æœ«æ—¥æœŸ
            year_ends = [date + pd.offsets.YearEnd(0) for date in years]

            # è¿‡æ»¤ç›®æ ‡æ•°æ®
            filtered = all_data_melted_df[
                (all_data_melted_df["æœºæ„åç§°"] == org)
                & (all_data_melted_df["æŒ‡æ ‡åç§°"] == indicator)
                & (all_data_melted_df["æ•°æ®æ—¥æœŸ"].isin(year_ends))
            ]

            # æœ‰æ•ˆæ€§æ£€æŸ¥åŸºç¡€æ•°æ®
            if filtered.empty:
                return "è®¡ç®—è¿‘3å¹´è¶‹åŠ¿æ—¶ï¼šæŸ¥è¯¢æŒ‡æ ‡æ•°æ®å‡ºé”™ï¼Œæ•°æ®é›†ä¸ºç©º"

            # æŒ‰æ—¥æœŸæ’åºåå»é‡ï¼ˆä¿ç•™æ¯ä¸ªå¹´åº¦æœ€åä¸€ä¸ªè®°å½•ï¼‰
            filtered = filtered.sort_values("æ•°æ®æ—¥æœŸ")
            dedup_data = filtered.drop_duplicates(subset=["æ•°æ®æ—¥æœŸ"], keep="last")

            # æ£€æŸ¥æ˜¯å¦åŒ…å«å®Œæ•´ä¸‰ä¸ªå¹´åº¦æ•°æ®
            existing_years = dedup_data["æ•°æ®æ—¥æœŸ"].unique()
            if not all(y in existing_years for y in year_ends):
                return "è®¡ç®—è¿‘3å¹´è¶‹åŠ¿æ—¶ï¼šæŸ¥è¯¢æŒ‡æ ‡æ•°æ®å‡ºé”™ï¼Œæ•°æ®æ—¥æœŸä¸å®Œæ•´ï¼Œæ•°æ®åº”åŒ…å«è¿‘3ä¸ªå¹´æœ«çš„æ•°æ®"

            # æŒ‰æ—¶é—´é¡ºåºæå–æŒ‡æ ‡å€¼ï¼ˆT-2ã€T-1ã€Tï¼‰
            trend_data = dedup_data.set_index("æ•°æ®æ—¥æœŸ").loc[year_ends]
            values = trend_data["æŒ‡æ ‡å€¼"].tolist()

            # æœ€ç»ˆæœ‰æ•ˆæ€§æ£€æŸ¥
            if len(values) != 3 or any(pd.isnull(values)):
                return "è®¡ç®—è¿‘3å¹´è¶‹åŠ¿æ—¶ï¼šæŸ¥è¯¢æŒ‡æ ‡æ•°æ®å‡ºé”™ï¼Œæ•°æ®æ—¥æœŸä¸å®Œæ•´ï¼Œæ•°æ®åº”åŒ…å«è¿‘3ä¸ªå¹´æœ«çš„æ•°æ®"

            v1, v2, v3 = values
            indicator_value = f"è¿‘3å¹´æŒ‡æ ‡å€¼ä¸ºï¼š{pp(indicator,v1)} {pp(indicator,v2)} {pp(indicator,v3)}"

            # æ£€æŸ¥ indicator æ˜¯å¦åŒ…å«åˆ—è¡¨ä¸­çš„å…³é”®è¯
            if any(keyword in indicator for keyword in ASC_ORDERED_KEYWORDS):
                rank = "ASC"
            else:
                rank = "DESC"

            # åˆ¤æ–­è¶‹åŠ¿ç±»å‹
            result = ""
            if v1 < v2 < v3:
                mean_of_trend = et("up", rank)
                return f"è¿‘3å¹´è¶‹åŠ¿ï¼šè¿ç»­2å¹´{mean_of_trend}ã€‚{indicator_value}"
            elif v1 > v2 > v3:
                mean_of_trend = et("down", rank)
                return f"è¿‘3å¹´è¶‹åŠ¿ï¼šè¿ç»­2å¹´{mean_of_trend}ã€‚{indicator_value}"
            elif v1 <= v2 and v2 > v3:
                mean_of_trend = et("down", rank)
                return f"è¿‘3å¹´è¶‹åŠ¿ï¼šå‡ºç°æ‹ç‚¹ï¼Œå¼€å§‹{mean_of_trend}ã€‚{indicator_value}"
            elif v1 >= v2 and v2 < v3:
                mean_of_trend = et("up", rank)
                return f"è¿‘3å¹´è¶‹åŠ¿ï¼šå‡ºç°æ‹ç‚¹ï¼Œå¼€å§‹{mean_of_trend}ã€‚{indicator_value}"
            elif v1 == v2 and v2 == v3:
                return f"è¿‘3å¹´è¶‹åŠ¿ï¼šæŒå¹³ã€‚{indicator_value}"
            else:
                return f"è¿‘3å¹´è¶‹åŠ¿ï¼šæ³¢åŠ¨ã€‚{indicator_value}"

            sentiment = get_sentiment(
                operator="TrendLast3YearsOperator",
                indicator=indicator,
                result_str=result,
            )
            return f"{sentiment}{result}"

        except Exception as e:
            return f"è®¡ç®—è¿‘3å¹´è¶‹åŠ¿æ—¶ï¼šæŸ¥è¯¢æŒ‡æ ‡æ•°æ®å‡ºé”™{str(e)}"


# class CompletionRateOperator(BaseOperator):
#     """å¤„ç†å®Œæˆç‡æ“ä½œç¬¦"""

#     @classmethod
#     def handle(
#         cls, config: dict, all_data_df: pd.DataFrame, all_data_melted_df: pd.DataFrame
#     ) -> str:
#         return f"å®Œæˆç‡ï¼š{config.get('rate', 'XX')}%ï¼ˆç¤ºä¾‹å®ç°ï¼‰"


class YearOverYearOperator(BaseOperator):
    """å¤„ç†æŒ‡æ ‡åŒæ¯”æ“ä½œç¬¦"""

    @classmethod
    def handle(
        cls, config: dict, all_data_df: pd.DataFrame, all_data_melted_df: pd.DataFrame
    ) -> str:
        try:
            # è·å–åŸºç¡€å‚æ•°
            target_date = pd.to_datetime(config["data_dt_rule"]).normalize()
            org = config["org_name"]
            indicator = config["indicator"]
        except KeyError as e:
            return f"è®¡ç®—å¹´åŒæ¯”æ—¶ï¼šæŸ¥è¯¢æŒ‡æ ‡æ•°æ®åŸºç¡€å‚æ•°å‡ºé”™{str(e)}"

        try:
            # è®¡ç®—å»å¹´åŒæœŸæ—¥æœŸ
            last_year_date = target_date - pd.DateOffset(years=1)
            last_year_month_end = last_year_date + pd.offsets.MonthEnd(0)

            # æŸ¥è¯¢å½“å‰æ•°æ®
            current_data = all_data_melted_df[
                (
                    pd.to_datetime(all_data_melted_df["æ•°æ®æ—¥æœŸ"]).dt.normalize()
                    == target_date
                )
                & (all_data_melted_df["æœºæ„åç§°"] == org)
                & (all_data_melted_df["æŒ‡æ ‡åç§°"] == indicator)
            ]

            # æŸ¥è¯¢å»å¹´åŒæœŸæ•°æ®
            last_year_data = all_data_melted_df[
                (
                    pd.to_datetime(all_data_melted_df["æ•°æ®æ—¥æœŸ"]).dt.normalize()
                    == last_year_month_end
                )
                & (all_data_melted_df["æœºæ„åç§°"] == org)
                & (all_data_melted_df["æŒ‡æ ‡åç§°"] == indicator)
            ]

            # æ•°æ®æœ‰æ•ˆæ€§æ£€æŸ¥
            for data, period in zip(
                [current_data, last_year_data], ["å½“å‰", "å»å¹´åŒæœŸ"]
            ):
                if len(data) == 0:
                    return f"è®¡ç®—å¹´åŒæ¯”æ—¶ï¼šæŸ¥è¯¢æŒ‡æ ‡æ•°æ®å‡ºé”™ï¼Œ{period}æ•°æ®è®°å½•æ•°ä¸º0ï¼Œè¯·æ£€æŸ¥æ•°æ®æ˜¯å¦å®Œæ•´"

                values = data["æŒ‡æ ‡å€¼"].dropna().unique()
                if len(values) != 1:
                    return f"è®¡ç®—å¹´åŒæ¯”æ—¶ï¼šæŸ¥è¯¢æŒ‡æ ‡æ•°æ®å‡ºé”™ï¼Œ{period}æ•°æ®è®°å½•æ•°ä¸ä¸º1ï¼Œè¯·æ£€æŸ¥æ•°æ®æ˜¯å¦é‡å¤"

            # æå–æ•°å€¼
            current_value = current_data["æŒ‡æ ‡å€¼"].iloc[0]
            last_year_value = last_year_data["æŒ‡æ ‡å€¼"].iloc[0]

            # è®¡ç®—å¢é•¿é¢å’Œå¢å¹…
            growth_amount = current_value - last_year_value
            try:
                growth_rate = (growth_amount / last_year_value) * 100
            except ZeroDivisionError:
                growth_rate = float("inf")

            # return f"åŒæ¯”æƒ…å†µ: åŒæ¯”å¢é•¿{growth_amount:.1f}ï¼ŒåŒæ¯”å¢å¹…{growth_rate:.1f}%ã€‚å»å¹´åŒæœŸï¼š{last_year_value:.1f}"
            # tmp_str1 = f"åŒæ¯”æ’å {pp(f"{indicator}_åŒæ¯”",-growth_amount)}" if "æ’å" in indicator else f"åŒæ¯”å¢é•¿ {pp(f"{indicator}_åŒæ¯”",growth_amount)}"
            tmp_str1 = f"{pp(f"{indicator}_åŒæ¯”",growth_amount)}"
            tmp_str2 = "" if "æ’å" in indicator else f"ï¼ŒåŒæ¯”å¢å¹… {growth_rate:.1f}%"

            sentiment = get_sentiment(
                operator="YearOverYearOperator",
                indicator=indicator,
                change_value=growth_amount
            )

            return f"{sentiment}å¹´åŒæ¯”æƒ…å†µï¼šåŒæ¯”å˜åŠ¨ {tmp_str1}{tmp_str2}ï¼Œå»å¹´åŒæœŸï¼š{pp(indicator,last_year_value)}"

        except Exception as e:
            return f"è®¡ç®—å¹´åŒæ¯”æ—¶ï¼šæŸ¥è¯¢æŒ‡æ ‡æ•°æ®å‡ºé”™ï¼š{str(e)}"


class MonthOverMonthOperator(BaseOperator):
    """å¤„ç†æŒ‡æ ‡æœˆç¯æ¯”æ“ä½œç¬¦"""

    @classmethod
    def handle(
        cls, config: dict, all_data_df: pd.DataFrame, all_data_melted_df: pd.DataFrame
    ) -> str:
        try:
            # è·å–åŸºç¡€å‚æ•°
            target_date = pd.to_datetime(config["data_dt_rule"]).normalize()
            org = config["org_name"]
            indicator = config["indicator"]
        except KeyError as e:
            return f"è®¡ç®—æœˆç¯æ¯”æ—¶ï¼šæŸ¥è¯¢æŒ‡æ ‡æ•°æ®åŸºç¡€å‚æ•°å‡ºé”™{str(e)}"

        try:
            # è®¡ç®—ä¸ŠæœˆåŒæœŸæ—¥æœŸ
            last_month_date = target_date - pd.DateOffset(months=1)

            last_month_month_end = last_month_date + pd.offsets.MonthEnd(0)
            # æŸ¥è¯¢å½“å‰æ•°æ®
            current_data = all_data_melted_df[
                (
                    pd.to_datetime(all_data_melted_df["æ•°æ®æ—¥æœŸ"]).dt.normalize()
                    == target_date
                )
                & (all_data_melted_df["æœºæ„åç§°"] == org)
                & (all_data_melted_df["æŒ‡æ ‡åç§°"] == indicator)
            ]

            # æŸ¥è¯¢ä¸ŠæœˆåŒæœŸæ•°æ®
            last_month_data = all_data_melted_df[
                (
                    pd.to_datetime(all_data_melted_df["æ•°æ®æ—¥æœŸ"]).dt.normalize()
                    == last_month_month_end
                )
                & (all_data_melted_df["æœºæ„åç§°"] == org)
                & (all_data_melted_df["æŒ‡æ ‡åç§°"] == indicator)
            ]

            # æ•°æ®æœ‰æ•ˆæ€§æ£€æŸ¥
            for data, period in zip(
                [current_data, last_month_data], ["å½“å‰", "ä¸ŠæœˆåŒæœŸ"]
            ):
                if len(data) == 0:
                    return f"è®¡ç®—æœˆç¯æ¯”æ—¶ï¼šæŸ¥è¯¢æŒ‡æ ‡æ•°æ®å‡ºé”™ï¼Œ{period}æ•°æ®è®°å½•æ•°ä¸º0ï¼Œè¯·æ£€æŸ¥æ•°æ®æ˜¯å¦å®Œæ•´"

                values = data["æŒ‡æ ‡å€¼"].dropna().unique()
                if len(values) != 1:
                    return f"è®¡ç®—æœˆç¯æ¯”æ—¶ï¼šæŸ¥è¯¢æŒ‡æ ‡æ•°æ®å‡ºé”™ï¼Œ{period}æ•°æ®è®°å½•æ•°ä¸ä¸º1ï¼Œè¯·æ£€æŸ¥æ•°æ®æ˜¯å¦é‡å¤"

            # æå–æ•°å€¼
            current_value = current_data["æŒ‡æ ‡å€¼"].iloc[0]
            last_month_value = last_month_data["æŒ‡æ ‡å€¼"].iloc[0]

            # è®¡ç®—å¢é•¿é¢å’Œå¢å¹…
            growth_amount = current_value - last_month_value
            try:
                growth_rate = (growth_amount / last_month_value) * 100
            except ZeroDivisionError:
                growth_rate = float("inf")

            # tmp_str = "" if "æ’å" in indicator else f"ï¼Œç¯æ¯”å¢å¹… {growth_rate:.1f}%"
            # return f"ç¯æ¯”æƒ…å†µ: ç¯æ¯”å¢é•¿ {pp(f"{indicator}_ç¯æ¯”",growth_amount)}{tmp_str}ã€‚ä¸ŠæœˆåŒæœŸï¼š{pp(indicator,last_month_value)}"

            tmp_str1 = f"{pp(f"{indicator}_ç¯æ¯”",growth_amount)}"
            tmp_str2 = "" if "æ’å" in indicator else f"ï¼Œç¯æ¯”å¢å¹… {growth_rate:.1f}%"

            sentiment = get_sentiment(
                operator="MonthOverMonthOperator",
                indicator=indicator,
                change_value=growth_amount,
            )
            return f"{sentiment}æœˆç¯æ¯”æƒ…å†µï¼šç¯æ¯”å˜åŠ¨ {tmp_str1}{tmp_str2}ï¼Œä¸ŠæœˆåŒæœŸï¼š{pp(indicator,last_month_value)}"

        except Exception as e:
            return f"è®¡ç®—æœˆç¯æ¯”æ—¶ï¼šæŸ¥è¯¢æŒ‡æ ‡æ•°æ®å‡ºé”™ï¼š{str(e)}"


def et(origianl_trend: str, rank: str) -> str:
    """è§£é‡Šè¶‹åŠ¿å«ä¹‰"""
    # up åŸå§‹æ•°æ®ä¸Šå‡ down åŸå§‹æ•°æ®ä¸‹é™
    # DESC é™åºæ’åº è¶Šå¤§è¶Šå¥½ ASC å‡åºæ’åº è¶Šå°è¶Šå¥½ å¦‚ æ’å
    if origianl_trend == "up" and rank == "DESC":
        return "å‘å¥½"
    elif origianl_trend == "down" and rank == "DESC":
        return "è½¬å·®"
    elif origianl_trend == "up" and rank == "ASC":
        return "è½¬å·®"
    elif origianl_trend == "down" and rank == "ASC":
        return "å‘å¥½"


def is_leap_year(year):
    return (year % 4 == 0 and year % 100 != 0) or (year % 400 == 0)


def get_sentiment(
    operator: str,
    indicator: str,
    result_str: str = None,
    change_value: float = None,
    group_rank_participant_count: int = None,
    rank: int = None,
) -> str:
    """
    åˆ¤æ–­æŒ‡æ ‡å˜åŠ¨çš„æƒ…ç»ª

    Args:
        operator: ç®—å­åç§°
        result_str: ç®—å­ç›‘æµ‹çš„ç»“æœå­—ç¬¦ä¸²
        indicator: æŒ‡æ ‡åç§°ï¼Œå¦‚æœä¸ºNoneåˆ™ä»result_strä¸­æå–

    Returns:
        str: 'Positive' è¡¨ç¤ºç§¯ææƒ…ç»ªï¼Œ'Negative' è¡¨ç¤ºæ¶ˆææƒ…ç»ªï¼Œ'Neutral' è¡¨ç¤ºä¸­æ€§æƒ…ç»ª
    """
    import re

    positive = "ğŸ”´"
    negative = "ğŸŸ¢"
    neutral  = "â–"
    # å¦‚æœæœªæä¾›indicatorï¼Œå°è¯•ä»result_strä¸­æå–
    if indicator is None:
        # å°è¯•ä»ç»“æœå­—ç¬¦ä¸²ä¸­æå–æŒ‡æ ‡åç§°
        indicator_match = re.search(r"æŒ‡æ ‡åç§°[ï¼š:](\S+)", result_str)
        if indicator_match:
            indicator = indicator_match.group(1)
        else:
            # å¦‚æœæ— æ³•æå–æŒ‡æ ‡åç§°ï¼Œä½¿ç”¨ç©ºå­—ç¬¦ä¸²
            indicator = ""

    # åˆ¤æ–­æŒ‡æ ‡æ˜¯å¦ä¸ºè´Ÿå‘æŒ‡æ ‡ï¼ˆåœ¨ASC_ORDERED_KEYWORDSä¸­çš„æŒ‡æ ‡ä¸ºè´Ÿå‘æŒ‡æ ‡ï¼‰
    is_negative_indicator = any(
        keyword in indicator for keyword in ASC_ORDERED_KEYWORDS
    )

    # æ ¹æ®ç®—å­ç±»å‹å¤„ç†ä¸åŒæƒ…å†µ
    # å½“æœŸå€¼ç®—å­
    if operator == "CurrentValueOperator":
        # å½“æœŸå€¼ç®—å­ï¼Œéƒ½è¿”å›ä¸­æ€§
        return neutral
    # è¶‹åŠ¿ç±»ç®—å­
    elif operator in [
        "TrendLast3MonthsOperator",
        "TrendLast3QuartersOperator",
        "TrendLast3YearsOperator",
    ]:
        # æ ¹æ®è¶‹åŠ¿æè¿°åˆ¤æ–­æƒ…ç»ª
        if "å‘å¥½" in result_str:
            return positive
        elif "è½¬å·®" in result_str:
            return negative
        elif "æŒå¹³" in result_str or "æ³¢åŠ¨" in result_str:
            return neutral
    # åŒç¯æ¯”ç®—å­
    elif operator in ["YearOverYearOperator", "MonthOverMonthOperator"]:
        if is_negative_indicator and change_value > 0:
            return positive
        elif is_negative_indicator and change_value < 0:
            return negative
        elif not is_negative_indicator and change_value > 0:
            return positive
        elif not is_negative_indicator and change_value < 0:
            return negative
        elif change_value == 0:
            return neutral
        else:
            return neutral
    # å¤„ç†ç»„å†…æ’åç®—å­
    elif operator in ["RankingOperator"]:
        pct = rank / group_rank_participant_count
        if pct < 1 / 3:
            return positive
        elif pct > 2 / 3:
            return positive
        else:
            return neutral
    # å…¶ä»–ç®—å­æƒ…å†µ
    else:
        return neutral
    # # åŒæ¯”å’Œç¯æ¯”ç®—å­
    # elif operator in ["YearOverYearOperator", "MonthOverMonthOperator"]:
    #     change_value = None

    #     # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼åŒ¹é…æ–‡æœ¬ä¸­çš„æ’åä½æ¬¡å˜åŒ–ä¿¡æ¯
    #     # åŒ¹é…æ ¼å¼ä¸º"æ’åä½æ¬¡ä¸Šå‡Xä½"æˆ–"æ’åä½æ¬¡ä¸‹é™Xä½"
    #     rank_change_match = re.search(r"æ’åä½æ¬¡(ä¸Šå‡|ä¸‹é™)(\d+)ä½", result_str)
    #     if rank_change_match:
    #         # è·å–å˜åŒ–æ–¹å‘(ä¸Šå‡/ä¸‹é™)
    #         # group(1)è¡¨ç¤ºè·å–æ­£åˆ™è¡¨è¾¾å¼ä¸­ç¬¬ä¸€ä¸ªæ•è·ç»„çš„å†…å®¹
    #         # ä¾‹å¦‚åœ¨æ­£åˆ™è¡¨è¾¾å¼"(ä¸Šå‡|ä¸‹é™)"ä¸­,æ‹¬å·å†…çš„å†…å®¹å°±æ˜¯ç¬¬ä¸€ä¸ªæ•è·ç»„
    #         # å¦‚æœåŒ¹é…åˆ°"ä¸Šå‡",åˆ™group(1)è¿”å›"ä¸Šå‡";å¦‚æœåŒ¹é…åˆ°"ä¸‹é™",åˆ™è¿”å›"ä¸‹é™"
    #         direction = rank_change_match.group(1)
    #         # è·å–å˜åŒ–çš„æ•°å€¼å¹¶è½¬ä¸ºæµ®ç‚¹æ•°
    #         value = float(rank_change_match.group(2))
    #         # å¦‚æœæ˜¯ä¸Šå‡,æ•°å€¼å–è´Ÿ;å¦‚æœæ˜¯ä¸‹é™,æ•°å€¼ä¿æŒä¸å˜
    #         # è¿™æ ·ç»Ÿä¸€äº†æ’åå˜åŒ–çš„è¡¨ç¤ºæ–¹å¼:è´Ÿå€¼è¡¨ç¤ºæ’åæå‡,æ­£å€¼è¡¨ç¤ºæ’åä¸‹é™
    #         change_value = -value

    # # å°è¯•åŒ¹é…Bpså€¼
    # elif "Bps" in result_str:
    #     bps_match = re.search(r"([+-]?\d+)Bps", result_str)
    #     if bps_match:
    #         change_value = float(bps_match.group(1)) / 10000  # è½¬æ¢å›å°æ•°å½¢å¼

    # # å°è¯•åŒ¹é…ç™¾åˆ†ç‚¹
    # elif "ä¸ªç™¾åˆ†ç‚¹" in result_str:
    #     percent_match = re.search(r"([+-]?\d+\.?\d*)ä¸ªç™¾åˆ†ç‚¹", result_str)
    #     if percent_match:
    #         change_value = float(percent_match.group(1)) / 100  # è½¬æ¢å›å°æ•°å½¢å¼

    # # å°è¯•åŒ¹é…ä¸€èˆ¬æ•°å€¼ï¼ˆå¸¦ç¬¦å·çš„æ•°å­—ï¼‰
    # elif not change_value:
    #     number_match = re.search(r"å˜åŠ¨\s+([+-]?\d+\.?\d*)", result_str)
    #     if number_match:
    #         change_value = float(number_match.group(1))
    #     else:
    #         # å¦‚æœä¸Šè¿°æ¨¡å¼éƒ½ä¸åŒ¹é…ï¼Œå°è¯•åŒ¹é…ä»»ä½•æ•°å­—
    #         general_number_match = re.search(r"([+-]?\d+\.?\d*)", result_str)
    #         if general_number_match:
    #             change_value = float(general_number_match.group(1))
    #         else:
    #             # å¦‚æœæ— æ³•æå–æ•°å€¼ï¼Œè¿”å›ä¸­æ€§æƒ…ç»ª
    #             return neutral

    # # åˆ¤æ–­å˜åŠ¨å€¼çš„æ­£è´Ÿ
    # is_positive_change = change_value > 0

    # # æ­£å‘æŒ‡æ ‡ï¼Œå˜åŠ¨ä¸ºæ­£ï¼Œä¸ºæ­£é¢ï¼›å˜åŠ¨ä¸ºè´Ÿï¼Œä¸ºè´Ÿé¢
    # # è´Ÿå‘æŒ‡æ ‡ï¼Œå˜åŠ¨ä¸ºæ­£ï¼Œä¸ºè´Ÿé¢ï¼›å˜åŠ¨ä¸ºè´Ÿï¼Œä¸ºæ­£é¢
    # if is_negative_indicator:
    #     return positive if not is_positive_change else "Negative"
    # else:
    #     return positive if is_positive_change else "Negative"

    # # æ’åç®—å­
    # elif operator == "RankingOperator":
    #     # æ’åç®—å­ï¼Œéœ€è¦æå–æ’åä¿¡æ¯
    #     rank_match = re.search(r"ç¬¬(\d+)å", result_str)
    #     if rank_match:
    #         rank_value = int(rank_match.group(1))
    #         total_match = re.search(r"ç»„å†…å…±(\d+)å®¶æœºæ„", result_str)
    #         if total_match:
    #             total = int(total_match.group(1))
    #             # æ’ååœ¨å‰ä¸‰åˆ†ä¹‹ä¸€ä¸ºæ­£é¢ï¼Œåä¸‰åˆ†ä¹‹ä¸€ä¸ºè´Ÿé¢
    #             if rank_value <= total / 3:
    #                 return positive
    #             elif rank_value > total * 2 / 3:
    #                 return negative
    #             else:
    #                 return neutral
    #         else:
    #             # æ— æ³•è·å–æ€»æ•°ï¼Œç®€å•åˆ¤æ–­
    #             return (
    #                 "Positive"
    #                 if rank_value <= 3
    #                 else ("Neutral" if rank_value <= 10 else "Negative")
    #             )
    #     return neutral

    # # é»˜è®¤æƒ…å†µï¼Œå°è¯•æå–æ•°å€¼
    # else:
    #     # å°è¯•åŒ¹é…ä»»ä½•æ•°å­—
    #     number_match = re.search(r"([+-]?\d+\.?\d*)", result_str)
    #     if number_match:
    #         change_value = float(number_match.group(1))
    #         is_positive_change = change_value > 0

    #         if is_negative_indicator:
    #             return positive if not is_positive_change else "Negative"
    #         else:
    #             return positive if is_positive_change else "Negative"

    #     return neutral
